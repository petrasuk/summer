{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-3 : Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Find the parameters for the following model with one weight and one bias variable\n",
    "\n",
    "![title](img/Day1-1-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the training data (실제 참값 데이타를 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.77636042e-02   9.68038023e-01   3.06955744e-02   1.47216499e-01\n",
      "   9.33517003e-04   5.18431425e-01   8.30147684e-01   1.17437251e-01\n",
      "   2.90193707e-01   5.65207362e-01   7.92811573e-01   1.10972025e-01\n",
      "   5.42888977e-02   9.63820636e-01   2.80752480e-01   2.85820454e-01\n",
      "   7.17859209e-01   3.62922817e-01   4.08129305e-01   6.89597905e-01\n",
      "   3.54913212e-02   4.09568287e-02   7.26809859e-01   8.64227891e-01\n",
      "   5.82166195e-01   8.32873046e-01   5.30579165e-02   5.45904934e-01\n",
      "   9.56791401e-01   1.87967986e-01   6.89753294e-01   5.98635912e-01\n",
      "   2.60724783e-01   5.97906053e-01   6.96163416e-01   2.60451198e-01\n",
      "   6.41551912e-01   8.45582187e-01   1.42486125e-01   4.17219132e-01\n",
      "   8.90343785e-01   6.41240418e-01   9.56185341e-01   4.86112446e-01\n",
      "   6.07389987e-01   4.79750365e-01   3.43626857e-01   7.83774018e-01\n",
      "   6.19254470e-01   4.44736749e-01   5.76064765e-01   7.44381070e-01\n",
      "   8.76927555e-01   9.73196387e-01   3.74731153e-01   7.39400685e-01\n",
      "   6.08138800e-01   8.57853591e-01   1.99671090e-01   5.84062114e-02\n",
      "   3.37667793e-01   3.83750468e-01   1.91786692e-01   5.21476150e-01\n",
      "   4.68629152e-01   5.14895797e-01   4.49089020e-01   1.22819118e-01\n",
      "   9.04631376e-01   7.57966518e-01   8.88945937e-01   2.51953661e-01\n",
      "   7.18834817e-01   3.89016747e-01   6.85943961e-01   4.37376946e-01\n",
      "   3.32005173e-01   7.00129867e-01   9.20153737e-01   1.11723274e-01\n",
      "   5.50827920e-01   4.15401280e-01   4.41688113e-02   6.00481629e-01\n",
      "   6.98754549e-01   6.05262578e-01   6.74990416e-02   3.31524640e-01\n",
      "   5.99131361e-02   6.60832942e-01   8.39624166e-01   2.23563150e-01\n",
      "   2.86416799e-01   8.57363045e-01   2.17687666e-01   5.11664391e-01\n",
      "   6.81693852e-01   8.93441260e-01   8.72407794e-01   7.60128140e-01]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.float32(np.random.rand(100))  # making 100 random values and store them in x_data\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13552725  2.93607616  1.06139112  1.294433    1.00186706  2.03686285\n",
      "  2.66029549  1.23487449  1.58038735  2.13041472  2.58562326  1.22194409\n",
      "  1.10857785  2.92764139  1.56150496  1.57164097  2.43571854  1.72584558\n",
      "  1.81625867  2.37919569  1.07098269  1.08191371  2.45361972  2.72845578\n",
      "  2.16433239  2.66574621  1.10611582  2.09180975  2.9135828   1.37593603\n",
      "  2.37950659  2.19727182  1.52144957  2.19581223  2.39232683  1.5209024\n",
      "  2.28310394  2.69116449  1.28497219  1.83443832  2.78068757  2.28248072\n",
      "  2.91237068  1.97222495  2.21477985  1.95950079  1.68725371  2.56754804\n",
      "  2.23850894  1.88947344  2.15212965  2.48876214  2.75385523  2.94639277\n",
      "  1.74946237  2.47880125  2.2162776   2.7157073   1.39934218  1.11681247\n",
      "  1.67533565  1.76750088  1.38357341  2.0429523   1.93725824  2.02979159\n",
      "  1.8981781   1.24563825  2.80926275  2.51593304  2.77789187  1.50390732\n",
      "  2.43766975  1.77803349  2.37188792  1.87475395  1.66401029  2.40025973\n",
      "  2.84030747  1.22344661  2.10165596  1.83080256  1.08833766  2.20096326\n",
      "  2.3975091   2.21052504  1.13499808  1.66304922  1.11982632  2.32166576\n",
      "  2.67924833  1.44712627  1.57283354  2.71472597  1.43537533  2.02332878\n",
      "  2.36338758  2.7868824   2.74481559  2.52025628]\n"
     ]
    }
   ],
   "source": [
    "y_data = 2 * x_data + 1    # generating the y_data according to the model of y = 2 * x + 1 \n",
    "                           # The parameters of this model are 2 and 1. These are the parameters that we want\n",
    "print(y_data)            #  to find through training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let the parameter b be 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W is another parameter which value we randomly set between -1 and 1\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# Define the model \n",
    "y = W * x_data + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# set the train operator which finds W and b that minimizes the loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.75731158] [ 2.31167841]\n",
      "20 [ 1.64430416] [ 1.19080019]\n",
      "40 [ 1.91629004] [ 1.04490328]\n",
      "60 [ 1.98029959] [ 1.01056755]\n",
      "80 [ 1.99536359] [ 1.00248706]\n",
      "100 [ 1.99890888] [ 1.00058532]\n",
      "120 [ 1.99974322] [ 1.00013781]\n",
      "140 [ 1.99993968] [ 1.00003231]\n",
      "160 [ 1.99998581] [ 1.00000763]\n",
      "180 [ 1.99999654] [ 1.00000179]\n"
     ]
    }
   ],
   "source": [
    "# Define the operation which initializes all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Open and run the session with the init operation\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Iterate the train operation 200 times and print the result after every 20 iterations.\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find the parameters of the following model with two the weight parameters and one bias parameter\n",
    "\n",
    "![title](img/Day1-1-6.png)\n",
    "\n",
    "(example brought from  https://gist.github.com/haje01/202ac276bace4b25dd3f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d33abef8791b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m# Make a 2-D training data set with 100 vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Make a 2-D training data set with 100 vectors\n",
    "x_data = np.float32(np.random.rand(2, 100))\n",
    "\n",
    "# Let W_true = [0.1, 0.2], b_true = 0.3.\n",
    "# and generate the trainig data y_data \n",
    "#  W_true = [0.1, 0.2], b_true = 0.3 are the true parameters we want to find\n",
    "\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let b = 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W is a 1x2 weight vector (initialized with random values between -1 ~ 1)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "\n",
    "# Multiply W with x_data and add b.\n",
    "\n",
    "y = tf.matmul(W, x_data) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function and the Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# Set the train operator which finds W and b to minimize the loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.881657   -0.31105733]] [ 0.33505285]\n",
      "20 [[ 0.24901     0.14225051]] [ 0.25259653]\n",
      "40 [[ 0.13863526  0.20323031]] [ 0.2782447]\n",
      "60 [[ 0.11241937  0.20544076]] [ 0.29071784]\n",
      "80 [[ 0.1045731   0.20286217]] [ 0.2961356]\n",
      "100 [[ 0.10179723  0.20127107]] [ 0.29840526]\n",
      "120 [[ 0.10072563  0.20053652]] [ 0.299344]\n",
      "140 [[ 0.10029603  0.20022249]] [ 0.29973051]\n",
      "160 [[ 0.10012123  0.20009169]] [ 0.29988933]\n",
      "180 [[ 0.10004971  0.20003769]] [ 0.29995456]\n"
     ]
    }
   ],
   "source": [
    "# Define the operation which initializes all variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Make a session and run the init operation\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Iterate 200 times the train operation\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
